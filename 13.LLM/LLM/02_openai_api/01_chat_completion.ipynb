{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d235a73f",
   "metadata": {},
   "source": [
    "### Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886147d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í™˜ê²½ì„¤ì •\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84067158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7894c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤ ì´ë¦„ì´ íŒë‹¤ë¼ê³  í–ˆì–´! ë§ì§€? íŒë‹¤ì•¼, ì •ë§ ê·€ì—¬ìš´ ì´ë¦„ì´ë„¤! ë” ì´ì•¼ê¸°í•´ì£¼ê³  ì‹¶ì€ ê²Œ ìˆìœ¼ë©´ ì•Œë ¤ì¤˜!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":\"ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³ , ìƒì„¸í•œ ì„¤ëª…ì„ ì˜í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.\"},\n",
    "        {\"role\":\"user\", \"content\":\"ì•ˆë…• ë‚˜ì˜ ì´ë¦„ì€ íŒë‹¤ì•¼!!\"},\n",
    "        {\"role\" : \"assistant\", \"content\" : \"ì•ˆë…•, íŒë‹¤ì•¼! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ! ì–´ë–»ê²Œ ì§€ë‚´ê³  ìˆì–´? ê¶ê¸ˆí•œ ì ì´ë‚˜ ì´ì•¼ê¸°í•˜ê³  ì‹¶ì€ ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§í•´ì¤˜!\"},\n",
    "        {\"role\": \"user\", \"content\" : \"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ???\"}\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=4096,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef813c",
   "metadata": {},
   "source": [
    "### stream ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5182bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¼ë¡ ì…ë‹ˆë‹¤! ì—¬ê¸°ì— ê¸´ ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê¸´ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ê¸°ìˆ  ë°œì „ê³¼ íŒ¨ëŸ¬ë‹¤ì„ì˜ ë³€í™”ëŠ” ìš°ë¦¬ ì‚¶ì˜ ëª¨ë“  ì¸¡ë©´ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ìš°ë¦¬ê°€ ì‚´ê³  ìˆëŠ” ì‹œëŒ€ëŠ” ì •ë³´ì™€ ì†Œí†µì˜ ì‹œëŒ€ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¸í„°ë„·ê³¼ ëª¨ë°”ì¼ ê¸°ìˆ ì˜ ë°œë‹¬ì€ ì‚¬ëŒë“¤ê³¼ì˜ ì†Œí†µ ë°©ì‹ì„ í˜ì‹ ì ìœ¼ë¡œ ë³€í™”ì‹œì¼°ìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ìš°ë¦¬ëŠ” ì¥ì†Œì— êµ¬ì• ë°›ì§€ ì•Šê³  ì‰½ê²Œ ì—°ê²°ë  ìˆ˜ ìˆìœ¼ë©°, ì‹¤ì‹œê°„ìœ¼ë¡œ ì •ë³´ë¥¼ êµí™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ê¸°ìˆ ë“¤ì€ êµìœ¡, ë¹„ì¦ˆë‹ˆìŠ¤, ê±´ê°• ê´€ë¦¬ ë“± ì—¬ëŸ¬ ë¶„ì•¼ì—ì„œë„ í° ë³€í™”ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì˜¨ë¼ì¸ êµìœ¡ í”Œë«í¼ì€ ì „ ì„¸ê³„ ì–´ë””ì„œë“ ì§€ êµìœ¡ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ì œê³µí•˜ë©°, ìˆ˜ë§ì€ ì‚¬ëŒë“¤ì´ ì–¸ì œë“ ì§€ ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì›ê²© ê·¼ë¬´ê°€ ë³´í¸í™”ë˜ë©´ì„œ ì§ì¥ì¸ë“¤ì€ ì—…ë¬´ì™€ ì¼ìƒìƒí™œì˜ ê· í˜•ì„ ë§ì¶œ ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ í™˜ê²½ì„ ê²½í—˜í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê±´ê°• ê´€ë¦¬ ë¶„ì•¼ì—ì„œë„ ê¸°ìˆ ì€ í˜ì‹ ì„ ì£¼ë„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì›ê²© ì§„ë£Œ, ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°, AI ê¸°ë°˜ ê±´ê°• ë¶„ì„ ë“±ì´ ëŒ€í‘œì ì¸ ì‚¬ë¡€ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë³€í™”ëŠ” í™˜ìë“¤ì—ê²Œ ë” ë‚˜ì€ ì¹˜ë£Œë¥¼ ì œê³µí•˜ê³ , ì˜ë£Œì§„ì´ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ì—…í•  ìˆ˜ ìˆë„ë¡ ë•ê³  ìˆìŠµë‹ˆë‹¤. ë°ì´í„° ë¶„ì„ê³¼ ì¸ê³µì§€ëŠ¥ì˜ ë°œì „ì€ ê°œì¸ ë§ì¶¤í˜• ì˜ë£Œ ì„œë¹„ìŠ¤ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬, í™˜ì ê°œê°œì¸ì˜ ê±´ê°• ìƒíƒœì— ë§ì¶˜ ìµœì ì˜ ì¹˜ë£Œ ë°©ì•ˆì„ ì œì‹œí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê·¸ë ‡ë‹¤ë©´ ì´ëŸ¬í•œ ê¸°ìˆ  ë°œì „ì´ ìš°ë¦¬ì˜ ì‚¶ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€ ë¬´ì—‡ì¼ê¹Œìš”? ê¸ì •ì ì¸ ì¸¡ë©´ë„ ìˆì§€ë§Œ ë¶€ì •ì ì¸ ì¸¡ë©´ë„ ì¡´ì¬í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì •ë³´ì˜ ê³¼ë„í•œ ì–‘ì€ ì˜¤íˆë ¤ ì‚¬ëŒë“¤ì„ í˜¼ë€ìŠ¤ëŸ½ê²Œ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë©°, ì˜ëª»ëœ ì •ë³´ê°€ ê¸‰ì†ë„ë¡œ í¼ì§ˆ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‚¬ì´ë²„ ë²”ì£„ì™€ ê°œì¸ì •ë³´ ìœ ì¶œ ë“±ì˜ ë¬¸ì œë„ ìš°ë¦¬ê°€ í•´ê²°í•´ì•¼ í•  ì¤‘ìš”í•œ ê³¼ì œê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê²°êµ­, ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ê¸°ìˆ  ë³€í™”ì— ì ì‘í•˜ë©´ì„œë„ ê·¸ì— ëŒ€í•œ ë¹„íŒì  ì‚¬ê³ ë¥¼ ê¸°ë¥´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê¸°ìˆ ì„ ë‹¨ìˆœíˆ ìˆ˜ìš©í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ê·¸ê²ƒì´ ì‚¬íšŒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê¹Šì´ ì´í•´í•˜ê³  ì´ì— ëŒ€í•œ ì±…ì„ê°ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë” ë‚˜ì€ ë¯¸ë˜ë¥¼ ë§Œë“¤ì–´ ë‚˜ê°ˆ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ë§ˆì§€ë§‰ìœ¼ë¡œ, ì•ìœ¼ë¡œì˜ ê¸°ìˆ ì´ ì–´ë–»ê²Œ ë°œì „í• ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ì€ ì–¸ì œë‚˜ ë…¼ë€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥, ë¸”ë¡ì²´ì¸, ìƒëª…ê³µí•™ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œì˜ í˜ì‹ ì´ ìš°ë¦¬ ì‚¬íšŒë¥¼ ì–´ë–»ê²Œ ë³€í™”ì‹œí‚¬ì§€ ì§€ì¼œë³´ëŠ” ê²ƒì€ ë§¤ìš° í¥ë¯¸ë¡œìš´ ì¼ì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì´ëŸ¬í•œ ë³€í™”ì— ì£¼ëª©í•˜ê³ , ì¤€ë¹„í•˜ë©°, ì ì‘í•  ìˆ˜ ìˆë‹¤ë©´ ë”ìš± ë°ì€ ë¯¸ë˜ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ë©”ì‹œì§€ê°€ ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ë¼ë©°, ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ê¸°ë¥¼ ê¸°ì›í•©ë‹ˆë‹¤!\n",
      "\n",
      "--- \n",
      "\n",
      "ì´ìƒì…ë‹ˆë‹¤. ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ë‚˜ ë‹¤ë¥¸ ìš”ì²­ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!ğŸ“ì‘ë‹µ ì™„ë£Œ!!ğŸ“\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI() # api_keyë¥¼ ì‘ì„±í•˜ì§€ ì•Šìœ¼ë©´, ìë™ìœ¼ë¡œ í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì°¸ì¡°\n",
    "\n",
    "stream_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\" : \"user\" , \"content\":\"ìŠ¤íŠ¸ë¦¼ í…ŒìŠ¤íŠ¸í•˜ëŠ”ë°, ê¸´ ì‘ë‹µë©”ì„¸ì§€ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”.\"}\n",
    "    ],\n",
    "    stream=True # ìƒì„±ë˜ëŠ” ë‹¨ì–´(í† í°)ì¡°ê°ë“¤ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê³„ì†í•´ì„œ ë³´ë‚´ì¤€ë‹¤.\n",
    ")\n",
    "\n",
    "for chunk in stream_response:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "print(\"ğŸ“ì‘ë‹µ ì™„ë£Œ!!ğŸ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91b126",
   "metadata": {},
   "source": [
    "### Token Counting\n",
    "\n",
    "- ì˜¨ë¼ì¸í…ŒìŠ¤íŠ¸ https://platform.openai.com/tokenizer\n",
    "- íŒŒì´ì¬í…ŒìŠ¤íŠ¸ tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0829480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.12.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\admin\\miniconda3\\envs\\pystudy_env\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\miniconda3\\envs\\pystudy_env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\miniconda3\\envs\\pystudy_env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\miniconda3\\envs\\pystudy_env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\miniconda3\\envs\\pystudy_env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n",
      "Using cached tiktoken-0.12.0-cp312-cp312-win_amd64.whl (878 kB)\n",
      "Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "\n",
      "   -------------------- ------------------- 1/2 [tiktoken]\n",
      "   ---------------------------------------- 2/2 [tiktoken]\n",
      "\n",
      "Successfully installed regex-2025.11.3 tiktoken-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5780e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "gpt35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "gpt4o = tiktoken.encoding_for_model(\"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc78a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "ì„œìš¸ì‹œë²„ìŠ¤ì¡°í•©ì€ ì´ë‹¬ 30ì¼ë¶€í„° '2026ë…„ ìƒˆí•´ í¬ë§ë²„ìŠ¤ ìº í˜ì¸'ë„ ì§„í–‰í•œë‹¤. ì†Œë°©ê´€ë“¤ì´ ì‘ì„±í•œ ìƒˆí•´ ì¸ì‚¬ ê¸€ê³¼ ê·¸ë¦¼ì„ ì‹œë‚´ë²„ìŠ¤ ì™¸ë¶€ì— ë¶€ì°©í•˜ëŠ” ìº í˜ì¸ì´ë‹¤.\n",
    "\n",
    "ì„œìš¸ì‹œë²„ìŠ¤ì¡°í•©ì€ ì‘ë…„ì— ì´ì–´ 2ë…„ì§¸ ì†Œë°©ê´€ ì‘ì› í–‰ì‚¬ë¥¼ ì´ì–´ê°€ê³  ìˆë‹¤. ì˜¬í•´ëŠ” ì†¡íŒŒì†Œë°©ì„œë¥¼ ë¹„ë¡¯í•´ ì´ 10ê°œ ì†Œë°©ì„œì— ì»¤í”¼ì°¨ ìŒë£Œë¥¼ ì§€ì›í•˜ê³  ë‹¤ìœ¡ì´ ì•¡ì 1ì²œ200ê°œ, ì„œìš¸ë¼ë©´ 400ìƒìë¥¼ ë‚˜ëˆ ì¤„ ê³„íšì´ë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "gpt35_tokens = gpt35.encode(text)\n",
    "gpt4o_tokens = gpt4o.encode(text)\n",
    "\n",
    "print(len(gpt35_tokens))\n",
    "print(len(gpt4o_tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
